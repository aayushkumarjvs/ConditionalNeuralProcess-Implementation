{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNP-Implementation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushkumarjvs/ConditionalNeuralProcess-Implementation/blob/master/CNP_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L00_V7VObZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuKG4j7Sbhl5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The CNP takes as input a `CNPRegressionDescription` namedtuple with fields:\n",
        "#   `query`: a tuple containing ((context_x, context_y), target_x)\n",
        "#   `target_y`: a tesor containing the ground truth for the targets to be\n",
        "#     predicted\n",
        "#   `num_total_points`: A vector containing a scalar that describes the total\n",
        "#     number of datapoints used (context + target)\n",
        "#   `num_context_points`: A vector containing a scalar that describes the number\n",
        "#     of datapoints used as context\n",
        "# The GPCurvesReader returns the newly sampled data in this format at each\n",
        "# iteration\n",
        "\n",
        "CNPRegressionDescription = collections.namedtuple(\n",
        "    \"CNPRegressionDescription\",\n",
        "    (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))\n",
        "\n",
        "\n",
        "class GPCurvesReader(object):\n",
        "  \"\"\"Generates curves using a Gaussian Process (GP).\n",
        "\n",
        "  Supports vector inputs (x) and vector outputs (y). Kernel is\n",
        "  mean-squared exponential, using the x-value l2 coordinate distance scaled by\n",
        "  some factor chosen randomly in a range. Outputs are independent gaussian\n",
        "  processes.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               batch_size,\n",
        "               max_num_context,\n",
        "               x_size=1,\n",
        "               y_size=1,\n",
        "               l1_scale=0.4,\n",
        "               sigma_scale=1.0,\n",
        "               testing=False):\n",
        "    \"\"\"Creates a regression dataset of functions sampled from a GP.\n",
        "\n",
        "    Args:\n",
        "      batch_size: An integer.\n",
        "      max_num_context: The max number of observations in the context.\n",
        "      x_size: Integer >= 1 for length of \"x values\" vector.\n",
        "      y_size: Integer >= 1 for length of \"y values\" vector.\n",
        "      l1_scale: Float; typical scale for kernel distance function.\n",
        "      sigma_scale: Float; typical scale for variance.\n",
        "      testing: Boolean that indicates whether we are testing. If so there are\n",
        "          more targets for visualization.\n",
        "    \"\"\"\n",
        "    self._batch_size = batch_size\n",
        "    self._max_num_context = max_num_context\n",
        "    self._x_size = x_size\n",
        "    self._y_size = y_size\n",
        "    self._l1_scale = l1_scale\n",
        "    self._sigma_scale = sigma_scale\n",
        "    self._testing = testing\n",
        "\n",
        "  def _gaussian_kernel(self, xdata, l1, sigma_f, sigma_noise=2e-2):\n",
        "    \"\"\"Applies the Gaussian kernel to generate curve data.\n",
        "\n",
        "    Args:\n",
        "      xdata: Tensor with shape `[batch_size, num_total_points, x_size]` with\n",
        "          the values of the x-axis data.\n",
        "      l1: Tensor with shape `[batch_size, y_size, x_size]`, the scale\n",
        "          parameter of the Gaussian kernel.\n",
        "      sigma_f: Float tensor with shape `[batch_size, y_size]`; the magnitude\n",
        "          of the std.\n",
        "      sigma_noise: Float, std of the noise that we add for stability.\n",
        "\n",
        "    Returns:\n",
        "      The kernel, a float tensor with shape\n",
        "      `[batch_size, y_size, num_total_points, num_total_points]`.\n",
        "    \"\"\"\n",
        "    num_total_points = tf.shape(xdata)[1]\n",
        "\n",
        "    # Expand and take the difference\n",
        "    xdata1 = tf.expand_dims(xdata, axis=1)  # [B, 1, num_total_points, x_size]\n",
        "    xdata2 = tf.expand_dims(xdata, axis=2)  # [B, num_total_points, 1, x_size]\n",
        "    diff = xdata1 - xdata2  # [B, num_total_points, num_total_points, x_size]\n",
        "\n",
        "    # [B, y_size, num_total_points, num_total_points, x_size]\n",
        "    norm = tf.square(diff[:, None, :, :, :] / l1[:, :, None, None, :])\n",
        "\n",
        "    norm = tf.reduce_sum(\n",
        "        norm, -1)  # [B, data_size, num_total_points, num_total_points]\n",
        "\n",
        "    # [B, y_size, num_total_points, num_total_points]\n",
        "    kernel = tf.square(sigma_f)[:, :, None, None] * tf.exp(-0.5 * norm)\n",
        "\n",
        "    # Add some noise to the diagonal to make the cholesky work.\n",
        "    kernel += (sigma_noise**2) * tf.eye(num_total_points)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "  def generate_curves(self):\n",
        "    \"\"\"Builds the op delivering the data.\n",
        "\n",
        "    Generated functions are `float32` with x values between -2 and 2.\n",
        "    \n",
        "    Returns:\n",
        "      A `CNPRegressionDescription` namedtuple.\n",
        "    \"\"\"\n",
        "    num_context = tf.random_uniform(\n",
        "        shape=[], minval=3, maxval=self._max_num_context, dtype=tf.int32)\n",
        "\n",
        "    # If we are testing we want to have more targets and have them evenly\n",
        "    # distributed in order to plot the function.\n",
        "    if self._testing:\n",
        "      num_target = 400\n",
        "      num_total_points = num_target\n",
        "      x_values = tf.tile(\n",
        "          tf.expand_dims(tf.range(-2., 2., 1. / 100, dtype=tf.float32), axis=0),\n",
        "          [self._batch_size, 1])\n",
        "      x_values = tf.expand_dims(x_values, axis=-1)\n",
        "    # During training the number of target points and their x-positions are\n",
        "    # selected at random\n",
        "    else:\n",
        "      num_target = tf.random_uniform(\n",
        "          shape=(), minval=2, maxval=self._max_num_context, dtype=tf.int32)\n",
        "      num_total_points = num_context + num_target\n",
        "      x_values = tf.random_uniform(\n",
        "          [self._batch_size, num_total_points, self._x_size], -2, 2)\n",
        "\n",
        "    # Set kernel parameters\n",
        "    l1 = (\n",
        "        tf.ones(shape=[self._batch_size, self._y_size, self._x_size]) *\n",
        "        self._l1_scale)\n",
        "    sigma_f = tf.ones(\n",
        "        shape=[self._batch_size, self._y_size]) * self._sigma_scale\n",
        "\n",
        "    # Pass the x_values through the Gaussian kernel\n",
        "    # [batch_size, y_size, num_total_points, num_total_points]\n",
        "    kernel = self._gaussian_kernel(x_values, l1, sigma_f)\n",
        "\n",
        "    # Calculate Cholesky, using double precision for better stability:\n",
        "    cholesky = tf.cast(tf.cholesky(tf.cast(kernel, tf.float64)), tf.float32)\n",
        "\n",
        "    # Sample a curve\n",
        "    # [batch_size, y_size, num_total_points, 1]\n",
        "    y_values = tf.matmul(\n",
        "        cholesky,\n",
        "        tf.random_normal([self._batch_size, self._y_size, num_total_points, 1]))\n",
        "\n",
        "    # [batch_size, num_total_points, y_size]\n",
        "    y_values = tf.transpose(tf.squeeze(y_values, 3), [0, 2, 1])\n",
        "\n",
        "    if self._testing:\n",
        "      # Select the targets\n",
        "      target_x = x_values\n",
        "      target_y = y_values\n",
        "\n",
        "      # Select the observations\n",
        "      idx = tf.random_shuffle(tf.range(num_target))\n",
        "      context_x = tf.gather(x_values, idx[:num_context], axis=1)\n",
        "      context_y = tf.gather(y_values, idx[:num_context], axis=1)\n",
        "\n",
        "    else:\n",
        "      # Select the targets which will consist of the context points as well as\n",
        "      # some new target points\n",
        "      target_x = x_values[:, :num_target + num_context, :]\n",
        "      target_y = y_values[:, :num_target + num_context, :]\n",
        "\n",
        "      # Select the observations\n",
        "      context_x = x_values[:, :num_context, :]\n",
        "      context_y = y_values[:, :num_context, :]\n",
        "\n",
        "    query = ((context_x, context_y), target_x)\n",
        "\n",
        "    return CNPRegressionDescription(\n",
        "        query=query,\n",
        "        target_y=target_y,\n",
        "        num_total_points=tf.shape(target_x)[1],\n",
        "        num_context_points=num_context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3hVGiATbp81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNP Encoder"
      ]
    },
    {
      "metadata": {
        "id": "3mcsUcxtbukG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeterministicEncoder(object):\n",
        "  \"\"\"The Encoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes):\n",
        "    \"\"\"CNP encoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the encoding MLP.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "\n",
        "  def __call__(self, context_x, context_y, num_context_points):\n",
        "    \"\"\"Encodes the inputs into one representation.\n",
        "\n",
        "    Args:\n",
        "      context_x: Tensor of size bs x observations x m_ch. For this 1D regression\n",
        "          task this corresponds to the x-values.\n",
        "      context_y: Tensor of size bs x observations x d_ch. For this 1D regression\n",
        "          task this corresponds to the y-values.\n",
        "      num_context_points: A tensor containing a single scalar that indicates the\n",
        "          number of context_points provided in this iteration.\n",
        "\n",
        "    Returns:\n",
        "      representation: The encoded representation averaged over all context \n",
        "          points.\n",
        "    \"\"\"\n",
        "\n",
        "    # Concatenate x and y along the filter axes\n",
        "    encoder_input = tf.concat([context_x, context_y], axis=-1)\n",
        "\n",
        "    # Get the shapes of the input and reshape to parallelise across observations\n",
        "    batch_size, _, filter_size = encoder_input.shape.as_list()\n",
        "    hidden = tf.reshape(encoder_input, (batch_size * num_context_points, -1))\n",
        "    hidden.set_shape((None, filter_size))\n",
        "\n",
        "    # Pass through MLP\n",
        "    with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
        "      for i, size in enumerate(self._output_sizes[:-1]):\n",
        "        hidden = tf.nn.relu(\n",
        "            tf.layers.dense(hidden, size, name=\"Encoder_layer_{}\".format(i)))\n",
        "\n",
        "      # Last layer without a ReLu\n",
        "      hidden = tf.layers.dense(\n",
        "          hidden, self._output_sizes[-1], name=\"Encoder_layer_{}\".format(i + 1))\n",
        "\n",
        "    # Bring back into original shape\n",
        "    hidden = tf.reshape(hidden, (batch_size, num_context_points, size))\n",
        "\n",
        "    # Aggregator: take the mean over all points\n",
        "    representation = tf.reduce_mean(hidden, axis=1)\n",
        "\n",
        "    return representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gny3i7gxb1KT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNP Decoder"
      ]
    },
    {
      "metadata": {
        "id": "YBwN9KHhb2u0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeterministicDecoder(object):\n",
        "  \"\"\"The Decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, output_sizes):\n",
        "    \"\"\"CNP decoder.\n",
        "\n",
        "    Args:\n",
        "      output_sizes: An iterable containing the output sizes of the decoder MLP \n",
        "          as defined in `basic.Linear`.\n",
        "    \"\"\"\n",
        "    self._output_sizes = output_sizes\n",
        "\n",
        "  def __call__(self, representation, target_x, num_total_points):\n",
        "    \"\"\"Decodes the individual targets.\n",
        "\n",
        "    Args:\n",
        "      representation: The encoded representation of the context\n",
        "      target_x: The x locations for the target query\n",
        "      num_total_points: The number of target points.\n",
        "\n",
        "    Returns:\n",
        "      dist: A multivariate Gaussian over the target points.\n",
        "      mu: The mean of the multivariate Gaussian.\n",
        "      sigma: The standard deviation of the multivariate Gaussian.\n",
        "    \"\"\"\n",
        "\n",
        "    # Concatenate the representation and the target_x\n",
        "    representation = tf.tile(\n",
        "        tf.expand_dims(representation, axis=1), [1, num_total_points, 1])\n",
        "    input = tf.concat([representation, target_x], axis=-1)\n",
        "\n",
        "    # Get the shapes of the input and reshape to parallelise across observations\n",
        "    batch_size, _, filter_size = input.shape.as_list()\n",
        "    hidden = tf.reshape(input, (batch_size * num_total_points, -1))\n",
        "    hidden.set_shape((None, filter_size))\n",
        "\n",
        "    # Pass through MLP\n",
        "    with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
        "      for i, size in enumerate(self._output_sizes[:-1]):\n",
        "        hidden = tf.nn.relu(\n",
        "            tf.layers.dense(hidden, size, name=\"Decoder_layer_{}\".format(i)))\n",
        "\n",
        "      # Last layer without a ReLu\n",
        "      hidden = tf.layers.dense(\n",
        "          hidden, self._output_sizes[-1], name=\"Decoder_layer_{}\".format(i + 1))\n",
        "\n",
        "    # Bring back into original shape\n",
        "    hidden = tf.reshape(hidden, (batch_size, num_total_points, -1))\n",
        "\n",
        "    # Get the mean an the variance\n",
        "    mu, log_sigma = tf.split(hidden, 2, axis=-1)\n",
        "\n",
        "    # Bound the variance\n",
        "    sigma = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
        "\n",
        "    # Get the distribution\n",
        "    dist = tf.contrib.distributions.MultivariateNormalDiag(\n",
        "        loc=mu, scale_diag=sigma)\n",
        "\n",
        "    return dist, mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRIGZbV4b7eR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNP Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "T8xEjpEjb6a-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeterministicModel(object):\n",
        "  \"\"\"The CNP model.\"\"\"\n",
        "\n",
        "  def __init__(self, encoder_output_sizes, decoder_output_sizes):\n",
        "    \"\"\"Initialises the model.\n",
        "\n",
        "    Args:\n",
        "      encoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
        "          the encoder. The last one is the size of the representation r.\n",
        "      decoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
        "          the decoder. The last element should correspond to the dimension of\n",
        "          the y * 2 (it encodes both mean and variance concatenated)\n",
        "    \"\"\"\n",
        "    self._encoder = DeterministicEncoder(encoder_output_sizes)\n",
        "    self._decoder = DeterministicDecoder(decoder_output_sizes)\n",
        "\n",
        "  def __call__(self, query, num_total_points, num_contexts, target_y=None):\n",
        "    \"\"\"Returns the predicted mean and variance at the target points.\n",
        "\n",
        "    Args:\n",
        "      query: Array containing ((context_x, context_y), target_x) where:\n",
        "          context_x: Array of shape batch_size x num_context x 1 contains the \n",
        "              x values of the context points.\n",
        "          context_y: Array of shape batch_size x num_context x 1 contains the \n",
        "              y values of the context points.\n",
        "          target_x: Array of shape batch_size x num_target x 1 contains the\n",
        "              x values of the target points.\n",
        "      target_y: The ground truth y values of the target y. An array of \n",
        "          shape batchsize x num_targets x 1.\n",
        "      num_total_points: Number of target points.\n",
        "\n",
        "    Returns:\n",
        "      log_p: The log_probability of the target_y given the predicted\n",
        "      distribution.\n",
        "      mu: The mean of the predicted distribution.\n",
        "      sigma: The variance of the predicted distribution.\n",
        "    \"\"\"\n",
        "\n",
        "    (context_x, context_y), target_x = query\n",
        "\n",
        "    # Pass query through the encoder and the decoder\n",
        "    representation = self._encoder(context_x, context_y, num_contexts)\n",
        "    dist, mu, sigma = self._decoder(representation, target_x, num_total_points)\n",
        "\n",
        "    # If we want to calculate the log_prob for training we will make use of the\n",
        "    # target_y. At test time the target_y is not available so we return None\n",
        "    if target_y is not None:\n",
        "      log_p = dist.log_prob(target_y)\n",
        "    else:\n",
        "      log_p = None\n",
        "\n",
        "    return log_p, mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yoyqXTzcF8X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the model and it's mean and variance values"
      ]
    },
    {
      "metadata": {
        "id": "rCSBK_zncMgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_functions(target_x, target_y, context_x, context_y, pred_y, var):\n",
        "  \"\"\"Plots the predicted mean and variance and the context points.\n",
        "  \n",
        "  Args: \n",
        "    target_x: An array of shape batchsize x number_targets x 1 that contains the\n",
        "        x values of the target points.\n",
        "    target_y: An array of shape batchsize x number_targets x 1 that contains the\n",
        "        y values of the target points.\n",
        "    context_x: An array of shape batchsize x number_context x 1 that contains \n",
        "        the x values of the context points.\n",
        "    context_y: An array of shape batchsize x number_context x 1 that contains \n",
        "        the y values of the context points.\n",
        "    pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
        "        predicted means of the y values at the target points in target_x.\n",
        "    pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
        "        predicted variance of the y values at the target points in target_x.\n",
        "  \"\"\"\n",
        "  # Plot everything\n",
        "  plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
        "  plt.plot(target_x[0], target_y[0], 'k:', linewidth=2)\n",
        "  plt.plot(context_x[0], context_y[0], 'ko', markersize=10)\n",
        "  plt.fill_between(\n",
        "      target_x[0, :, 0],\n",
        "      pred_y[0, :, 0] - var[0, :, 0],\n",
        "      pred_y[0, :, 0] + var[0, :, 0],\n",
        "      alpha=0.2,\n",
        "      facecolor='#65c9f7',\n",
        "      interpolate=True)\n",
        "\n",
        "  # Make the plot pretty\n",
        "  plt.yticks([-2, 0, 2], fontsize=16)\n",
        "  plt.xticks([-2, 0, 2], fontsize=16)\n",
        "  plt.ylim([-2, 2])\n",
        "  plt.grid('off')\n",
        "  ax = plt.gca()\n",
        "  ax.set_axis_bgcolor('white')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k4WhEh29cPT8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Running the Conditional Neural Process Model - Training\"\"\"\n",
        "TRAINING_ITERATIONS = int(2e5)\n",
        "MAX_CONTEXT_POINTS = 10\n",
        "PLOT_AFTER = int(2e4)\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oJ27r8AEctEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train dataset\n",
        "dataset_train = GPCurvesReader(\n",
        "    batch_size=64, max_num_context=MAX_CONTEXT_POINTS)\n",
        "data_train = dataset_train.generate_curves()\n",
        "\n",
        "# Test dataset\n",
        "dataset_test = GPCurvesReader(\n",
        "    batch_size=1, max_num_context=MAX_CONTEXT_POINTS, testing=True)\n",
        "data_test = dataset_test.generate_curves()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gi7FE438cvw2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sizes of the layers of the MLPs for the encoder and decoder\n",
        "# The final output layer of the decoder outputs two values, one for the mean and\n",
        "# one for the variance of the prediction at the target location\n",
        "encoder_output_sizes = [128, 128, 128, 128]\n",
        "decoder_output_sizes = [128, 128, 2]\n",
        "\n",
        "# Define the model\n",
        "model = DeterministicModel(encoder_output_sizes, decoder_output_sizes)\n",
        "\n",
        "# Define the loss\n",
        "log_prob, _, _ = model(data_train.query, data_train.num_total_points,\n",
        "                       data_train.num_context_points, data_train.target_y)\n",
        "loss = -tf.reduce_mean(log_prob)\n",
        "\n",
        "# Get the predicted mean and variance at the target points for the testing set\n",
        "_, mu, sigma = model(data_test.query, data_test.num_total_points,\n",
        "                     data_test.num_context_points)\n",
        "\n",
        "# Set up the optimizer and train step\n",
        "optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "train_step = optimizer.minimize(loss)\n",
        "init = tf.initialize_all_variables()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiaxtASkc1gZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "783b0ad6-12fd-4817-8a4c-979d6b0e5339"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "\n",
        "  for it in range(TRAINING_ITERATIONS):\n",
        "    sess.run([train_step])\n",
        "\n",
        "    # Plot the predictions in `PLOT_AFTER` intervals\n",
        "    if it % PLOT_AFTER == 0:\n",
        "      loss_value, pred_y, var, target_y, whole_query = sess.run(\n",
        "          [loss, mu, sigma, data_test.target_y, data_test.query])\n",
        "\n",
        "      (context_x, context_y), target_x = whole_query\n",
        "      print('Iteration: {}, loss: {}'.format(it, loss_value))\n",
        "\n",
        "      # Plot the prediction and the context\n",
        "      plot_functions(target_x, target_y, context_x, context_y, pred_y, var)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0, loss: 1.5410534143447876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py:424: MatplotlibDeprecationWarning: \n",
            "Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
            "  warn_deprecated(\"2.2\", \"Passing one of 'on', 'true', 'off', 'false' as a \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ee1ec05e33f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# Plot the prediction and the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mplot_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-5b7f65c37dca>\u001b[0m in \u001b[0;36mplot_functions\u001b[0;34m(target_x, target_y, context_x, context_y, pred_y, var)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_bgcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'set_axis_bgcolor'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFVCAYAAADR+vcXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/g+4Rn38elGg1QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}